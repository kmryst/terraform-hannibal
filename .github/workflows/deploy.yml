# ğŸš¨ é‡è¦: ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æ‰‹å‹•ä½œæˆã—ã¦ãã ã•ã„
#
# 1. ECRãƒªãƒã‚¸ãƒˆãƒª
# aws ecr create-repository --repository-name nestjs-hannibal-3 --region ap-northeast-1
#
# 2. S3ãƒã‚±ãƒƒãƒˆï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰
# aws s3 mb s3://nestjs-hannibal-3-frontend --region ap-northeast-1
#
# 3. CloudFront OAC
# aws cloudfront create-origin-access-control --name nestjs-hannibal-3-oac --origin-access-control-origin-type s3 --signing-behavior always --signing-protocol sigv4 --region us-east-1
#
# 4. ã‚«ã‚¹ã‚¿ãƒ IAMãƒãƒªã‚·ãƒ¼é©ç”¨
# cd terraform/backend && terraform apply -target="aws_iam_policy.hannibal_terraform_policy" -target="aws_iam_user_policy_attachment.hannibal_terraform_policy" -auto-approve
#
# ç†ç”±: æ¨©é™ã‚¨ãƒ©ãƒ¼å›é¿ã€CI/CDå®‰å®šæ€§å‘ä¸Šã€å®Ÿè¡Œæ™‚é–“çŸ­ç¸®



# C:\code\javascript\nestjs-hannibal-3\.github\workflows\deploy.yml

name: Deploy NestJS Hannibal App

# on: # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒˆãƒªã‚¬ãƒ¼ã‚’å®šç¾©
#   pull_request:
#     branches: [feature/github-actions]
#   push:
#     branches: [feature/github-actions]

on:
  workflow_dispatch:

jobs:
  test:
    # (å¤‰æ›´ãªã—)
    runs-on: ubuntu-latest # ã“ã®ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œã™ã‚‹ä»®æƒ³ãƒã‚·ãƒ³
    steps: # step: æ‰‹é †
      - name: Checkout code
        uses: actions/checkout@v4 # GitHubãŒæä¾›ã™ã‚‹å…¬å¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ã€ãƒªãƒã‚¸ãƒˆãƒªã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆï¼ˆå–å¾—ï¼‰ã—ã¾ã™
      - name: Setup Node.js for Backend
        uses: actions/setup-node@v3 # GitHubãŒæä¾›ã™ã‚‹å…¬å¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ã€æŒ‡å®šã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Node.jsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™
        with: # usesã§æŒ‡å®šã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«æ¸¡ã™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¨­å®šå€¤ï¼‰ã‚’å®šç¾©ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã™
          node-version: '20'
          cache: 'npm' # npmã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã“ã¨ã§ã€ä¾å­˜é–¢ä¿‚ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é«˜é€ŸåŒ–ã—ã¾ã™
          cache-dependency-path: package-lock.json
      - name: Install Backend Dependencies
        run: npm ci # clean install
      - name: Run Backend Tests
        run: npm test
      - name: Setup Node.js for Frontend
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: client/package-lock.json
      - name: Install Frontend Dependencies
        run: npm ci
        working-directory: ./client
      - name: Run Frontend Tests
        run: echo "Frontend tests would run here (e.g., npm run test)"
        # e.g. ãƒ©ãƒ†ãƒ³èª "exempli gratia" ä¾‹ãˆã°
        working-directory: ./client

  deploy:
    # (å¤‰æ›´ãªã—)
    needs: test # testãŒæˆåŠŸã—ãŸå ´åˆã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    # github ã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã®çŠ¶æ³ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’è¡¨ã™ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã€ã‚¤ãƒ™ãƒ³ãƒˆã‚„ãƒ–ãƒ©ãƒ³ãƒãªã©ã®æƒ…å ±ã‚’æä¾›ã—ã¾ã™
    # ãƒ–ãƒ©ãƒ³ãƒã®å‚ç…§ã¯ refs/heads/<ãƒ–ãƒ©ãƒ³ãƒå> ã¨ã„ã†å½¢å¼ã§è¡¨ç¾ã•ã‚Œã¾ã™
    runs-on: ubuntu-latest
    outputs: # ã“ã®ã‚¸ãƒ§ãƒ–ã§ç”Ÿæˆã—ãŸå€¤ã‚’ä»–ã®ã‚¸ãƒ§ãƒ–ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹(ä»Šã¯ä½¿ã£ã¦ãªã„)
      s3_bucket_name: ${{ steps.get_terraform_outputs.outputs.s3_bucket_name }}
      cloudfront_distribution_id: ${{ steps.get_terraform_outputs.outputs.cloudfront_distribution_id }}
      cloudfront_domain_name: ${{ steps.get_terraform_outputs.outputs.cloudfront_domain_name }}

    steps:
      # - name: ã‹ã‚‰å§‹ã¾ã‚‹å„ãƒ–ãƒ­ãƒƒã‚¯ãŒ step ã§ã™
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.0.0
      - name: Install jq # JSONãƒ‡ãƒ¼ã‚¿ã‚’query(æ¤œç´¢ã€åŠ å·¥)ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«
        run: sudo apt-get update && sudo apt-get install -y jq
        # apt-get ã¯ã€ŒAdvanced Package Toolã€ã®ç•¥ã§ã€Debianç³»Linuxï¼ˆUbuntuãªã©ï¼‰ã§ä½¿ã‚ã‚Œã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ã‚³ãƒãƒ³ãƒ‰ã§ã™

      # æ—¢å­˜ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šé™¤ï¼ˆãƒªã‚½ãƒ¼ã‚¹ç«¶åˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
      # ğŸ“ æ³¨æ„: ECRãƒªãƒã‚¸ãƒˆãƒªã¯æ‰‹å‹•ä½œæˆæ¸ˆã¿ã®ãŸã‚å‰Šé™¤ã—ã¾ã›ã‚“
      - name: Clean up existing AWS resources
        run: |
          echo "Cleaning up existing AWS resources to avoid conflicts..."

          # ğŸ“ ECRãƒªãƒã‚¸ãƒˆãƒªã¯æ‰‹å‹•ä½œæˆæ¸ˆã¿ã®ãŸã‚å‰Šé™¤ã‚’ã‚¹ã‚­ãƒƒãƒ—
          # ç†ç”±: æ¨©é™ã‚¨ãƒ©ãƒ¼å›é¿ã€CI/CDå®‰å®šæ€§å‘ä¸Šã€å®Ÿè¡Œæ™‚é–“çŸ­ç¸®
          echo "Skipping ECR deletion - using pre-created repository"

          # ECSã‚µãƒ¼ãƒ“ã‚¹å‰Šé™¤
          aws ecs update-service --cluster nestjs-hannibal-3-cluster --service nestjs-hannibal-3-api-service --desired-count 0 --region ap-northeast-1 2>/dev/null || echo "ECS service not found"
          sleep 10
          aws ecs delete-service --cluster nestjs-hannibal-3-cluster --service nestjs-hannibal-3-api-service --force --region ap-northeast-1 2>/dev/null || echo "ECS service not found"

          # ECSã‚¯ãƒ©ã‚¹ã‚¿å‰Šé™¤
          aws ecs delete-cluster --cluster nestjs-hannibal-3-cluster --region ap-northeast-1 2>/dev/null || echo "ECS cluster not found"

          # ALBå‰Šé™¤
          ALB_ARN=$(aws elbv2 describe-load-balancers --names nestjs-hannibal-3-alb --region ap-northeast-1 --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")
          if [ "$ALB_ARN" != "None" ] && [ "$ALB_ARN" != "null" ]; then
            aws elbv2 delete-load-balancer --load-balancer-arn "$ALB_ARN" --region ap-northeast-1
            echo "Waiting for ALB deletion..."
            sleep 60
          fi

          # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤
          TG_ARN=$(aws elbv2 describe-target-groups --names nestjs-hannibal-3-tg --region ap-northeast-1 --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "None")
          if [ "$TG_ARN" != "None" ] && [ "$TG_ARN" != "null" ]; then
            aws elbv2 delete-target-group --target-group-arn "$TG_ARN" --region ap-northeast-1
          fi

          # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤ï¼ˆALBå‰Šé™¤å¾Œã«å®Ÿè¡Œï¼‰
          echo "Waiting for security group dependencies to clear..."
          sleep 30

          SG_ECS_ID=$(aws ec2 describe-security-groups --group-names nestjs-hannibal-3-ecs-service-sg --region ap-northeast-1 --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "None")
          if [ "$SG_ECS_ID" != "None" ] && [ "$SG_ECS_ID" != "null" ]; then
            aws ec2 delete-security-group --group-id "$SG_ECS_ID" --region ap-northeast-1 2>/dev/null || echo "Security group deletion failed (dependencies may exist)"
          fi

          SG_ALB_ID=$(aws ec2 describe-security-groups --group-names nestjs-hannibal-3-alb-sg --region ap-northeast-1 --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "None")
          if [ "$SG_ALB_ID" != "None" ] && [ "$SG_ALB_ID" != "null" ]; then
            aws ec2 delete-security-group --group-id "$SG_ALB_ID" --region ap-northeast-1 2>/dev/null || echo "Security group deletion failed (dependencies may exist)"
          fi

          # IAMãƒ­ãƒ¼ãƒ«å‰Šé™¤
          aws iam detach-role-policy --role-name nestjs-hannibal-3-ecs-task-execution-role --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy 2>/dev/null || echo "IAM role policy not found"
          aws iam delete-role --role-name nestjs-hannibal-3-ecs-task-execution-role 2>/dev/null || echo "IAM role not found"

          # ç›£è¦–ãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤ï¼ˆCloudWatch Alarms, SNS Topic, Dashboardï¼‰
          echo "Cleaning up monitoring resources..."
          
          # CloudWatch Alarmså‰Šé™¤
          aws cloudwatch delete-alarms --alarm-names \
            "nestjs-hannibal-3-ecs-cpu-high" \
            "nestjs-hannibal-3-ecs-memory-high" \
            "nestjs-hannibal-3-ecs-task-stopped" \
            "nestjs-hannibal-3-rds-cpu-high" \
            "nestjs-hannibal-3-rds-connections-high" \
            "nestjs-hannibal-3-alb-response-time-high" \
            "nestjs-hannibal-3-alb-5xx-error-rate-high" \
            --region ap-northeast-1 2>/dev/null || echo "Alarms not found"
          
          # CloudWatch Dashboardå‰Šé™¤
          aws cloudwatch delete-dashboards --dashboard-names "hannibal-system-dashboard" --region ap-northeast-1 2>/dev/null || echo "Dashboard not found"
          
          # SNS Topicå‰Šé™¤
          SNS_TOPIC_ARN=$(aws sns list-topics --region ap-northeast-1 --query 'Topics[?contains(TopicArn, `nestjs-hannibal-3-alerts`)].TopicArn' --output text 2>/dev/null || echo "None")
          if [ "$SNS_TOPIC_ARN" != "None" ] && [ "$SNS_TOPIC_ARN" != "" ]; then
            aws sns delete-topic --topic-arn "$SNS_TOPIC_ARN" --region ap-northeast-1 2>/dev/null || echo "SNS topic deletion failed"
          fi

          # CloudWatchãƒ­ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤
          aws logs delete-log-group --log-group-name /ecs/nestjs-hannibal-3-api-task --region ap-northeast-1 2>/dev/null || echo "Log group not found"

          # RDSå‰Šé™¤ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤å‰ã«å®Ÿè¡Œï¼‰
          aws rds delete-db-instance --db-instance-identifier nestjs-hannibal-3-postgres --skip-final-snapshot --region ap-northeast-1 2>/dev/null || echo "RDS instance not found"
          echo "Waiting for RDS deletion..."
          sleep 60

          # RDSã‚µãƒ–ãƒãƒƒãƒˆã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤
          aws rds delete-db-subnet-group --db-subnet-group-name nestjs-hannibal-3-db-subnet-group --region ap-northeast-1 2>/dev/null || echo "DB subnet group not found"

          # RDSã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤
          SG_RDS_ID=$(aws ec2 describe-security-groups --group-names nestjs-hannibal-3-rds-sg --region ap-northeast-1 --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "None")
          if [ "$SG_RDS_ID" != "None" ] && [ "$SG_RDS_ID" != "null" ]; then
            aws ec2 delete-security-group --group-id "$SG_RDS_ID" --region ap-northeast-1 2>/dev/null || echo "RDS security group deletion failed"
          fi

          echo "Cleanup completed (errors are expected if resources don't exist)"
        continue-on-error: true
      - name: Terraform Init (Backend)
        id: init-backend
        run: yes | terraform init
        working-directory: ./terraform/backend
      - name: Terraform Plan (Backend)
        id: plan-backend
        run: terraform plan -no-color -var="client_url_for_cors="
        # -no-color ã¯ã€Terraformã®å‡ºåŠ›ã‚’ã€Œè‰²ãªã—ï¼ˆç™½é»’ï¼‰ã€ã«ã—ã¦ãƒ­ã‚°ã‚’è¦‹ã‚„ã™ãã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™
        # -var="client_url_for_cors="  terraform/backend/main.ts ã®å¤‰æ•° client_url_for_cors ã«ç©ºæ–‡å­—åˆ—ã‚’æ¸¡ã—ã¦ã„ã‚‹æŒ‡å®šã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€CORSè¨­å®šç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆURLãŒä¸€æ™‚çš„ã«æœªè¨­å®šã®çŠ¶æ…‹ã§ terraform plan ã‚’å®Ÿè¡Œã§ãã¾ã™
        working-directory: ./terraform/backend
        continue-on-error: true
      - name: Terraform Apply (Backend)
        id: apply-backend
        run:
          | # ãƒ‘ã‚¤ãƒ—è¨˜å·ã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã€ãã®ä¸‹ã«ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã—ã¦è¤‡æ•°è¡Œã®ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’è¨˜è¿°ã§ãã¾ã™
          terraform apply -auto-approve -no-color -var="client_url_for_cors="
          terraform output -json > ../tf_outputs_backend.json
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ãŠãã“ã¨ã§ã€Œåˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®Terraformã€ã‚„ã€Œjqã‚³ãƒãƒ³ãƒ‰ã€ãªã©ã§ã‚‚å€¤ã‚’ä½¿ã„å›ã›ã‚‹
        working-directory: ./terraform/backend

      - name: Terraform Init (Frontend)
        id: init-frontend
        run: yes | terraform init
        working-directory: ./terraform/frontend
      - name: Terraform Plan (Frontend)
        id: plan-frontend

        run: terraform plan -no-color -var="api_alb_dns_name=$(jq -r '.alb_dns_name.value' ../tf_outputs_backend.json)"
        # $()ã€€ã‚³ãƒãƒ³ãƒ‰ç½®æ›ã€ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡ŒçµæœãŒåŸ‹ã‚è¾¼ã¾ã‚Œã‚‹
        # jq -rã€€--raw-output æŠ½å‡ºã—ãŸå€¤ã‚’ã€Œãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆãªã—ã®ç”Ÿã®æ–‡å­—åˆ—ï¼ˆrawï¼‰ã€ã§å‡ºåŠ›ã—ã¾ã™
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆAPIï¼‰ã® ALB ã®DNSåã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®Terraformè¨­å®šã«å‹•çš„ã«åæ˜ ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™
        # ../tf_outputs_backend.json: GitHub ã‚µãƒ¼ãƒä¸Šã«ä½œã‚‰ã‚Œã‚‹ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« ã®ä¸­ã® .alb_dns_name ã‚­ãƒ¼ã®.value ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹

        working-directory: ./terraform/frontend
        continue-on-error: true
      - name: ğŸš€ Deploy Frontend Infrastructure
        run: |
          echo "ğŸš€ Deploying frontend resources..."
          yes | terraform init
          # CloudFrontã‚‚å«ã‚ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ãŸã‚ã€enable_cloudfront=trueã§apply
          terraform apply -auto-approve -var="api_alb_dns_name=$(jq -r '.alb_dns_name.value' ../tf_outputs_backend.json)" -var="enable_cloudfront=true"
          echo "âœ… Frontend infrastructure deployed"
        working-directory: ./terraform/frontend
      - name: Get Terraform Outputs (Frontend)
        id: get_terraform_outputs
        # shell
        run: |
          echo "Retrieving Terraform outputs (frontend)..."
          cd ./terraform/frontend
          terraform output -json > tf_outputs.json
          echo "--- Terraform Outputs (JSON) ---"
          cat tf_outputs.json
          echo "--------------------------------"

          cd ../..
          # 2éšå±¤ä¸Šã«ç§»å‹•ã™ã‚‹

          echo "s3_bucket_name=$(jq -r '.s3_bucket_name.value' ./terraform/frontend/tf_outputs.json)" >> $GITHUB_OUTPUT
          # echo ã§æ–‡å­—åˆ—ã‚’ä½œã‚Šã€>> ã§$GITHUB_OUTPUTã«è¿½è¨˜ã™ã‚‹
          # $GITHUB_OUTPUT ã¯ã€ŒGitHub Actionsã®åŒã˜ã‚¸ãƒ§ãƒ–å†…ã®ä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å‚ç…§ã™ã‚‹ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã€ã§ã™
          # ${{ steps.get_terraform_outputs.outputs.s3_bucket_name }} ã“ã‚ŒãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ 

          echo "cloudfront_domain_name=$(jq -r '.cloudfront_domain_name.value' ./terraform/frontend/tf_outputs.json)" >> $GITHUB_OUTPUT
          echo "cloudfront_distribution_id=$(jq -r '.cloudfront_distribution_id.value' ./terraform/frontend/tf_outputs.json)" >> $GITHUB_OUTPUT

          # å¤ã„ã‚„ã‚Šæ–¹ ä¸è¦
          # echo "::set-output name=s3_bucket_name::$(jq -r '.s3_bucket_name.value' ./terraform/frontend/tf_outputs.json)"
          # echo "::set-output name=cloudfront_domain_name::$(jq -r '.cloudfront_domain_name.value' ./terraform/frontend/tf_outputs.json)"
          # echo "::set-output name=cloudfront_distribution_id::$(jq -r '.cloudfront_distribution_id.value' ./terraform/frontend/tf_outputs.json)"

        working-directory: ./
        # ã“ã® step ã®é–‹å§‹æ™‚ç‚¹ã§ã€ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§é–‹å§‹ã™ã‚‹

      - name: Update CLIENT_URL in .env
        run: |
          sed -i "s|^CLIENT_URL=.*$|CLIENT_URL=https://hamilcar-hannibal.click|" .env

      - name: Update VITE_GRAPHQL_ENDPOINT in client/.env.production
        run: |
          sed -i "s|^VITE_GRAPHQL_ENDPOINT=.*$|VITE_GRAPHQL_ENDPOINT=https://hamilcar-hannibal.click/api/graphql|" client/.env.production

      # CloudFrontãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’CORSç”¨ã«backendã¸å†é©ç”¨
      - name: Terraform Apply (Backend, CORS Update)
        id: apply-backend-cors
        run: terraform apply -auto-approve -no-color -var="client_url_for_cors=https://hamilcar-hannibal.click"
        working-directory: ./terraform/backend
      - name: Setup Node.js for Frontend Build
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: client/package-lock.json
      - name: Install Frontend Dependencies for Build
        run: npm ci
        working-directory: ./client
      - name: Build Frontend
        run: npm run build
        working-directory: ./client
      - name: Deploy Frontend to S3
        run: |
          # (å†…å®¹ã¯å¤‰æ›´ãªã—)
          S3_BUCKET="${{ steps.get_terraform_outputs.outputs.s3_bucket_name }}"

          if [ -z "$S3_BUCKET" ]; then echo "::error::S3 bucket name not found."; exit 1; fi 
          # -z zero length
          # if ãŒ true ãªã‚‰ then ã‚’å®Ÿè¡Œã™ã‚‹
          # ::error:: ::warning:: ::notice:: GitHub Actionsç‹¬è‡ªã®ãƒ­ã‚°æ³¨é‡ˆæ©Ÿèƒ½ã§ã™
          # exit 1 ç•°å¸¸çµ‚äº†

          echo "Deploying frontend to bucket: $S3_BUCKET"
          aws s3 sync ./client/dist "s3://$S3_BUCKET" --delete
          # --delete S3ãƒã‚±ãƒƒãƒˆå´ã«ã‚ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«å‰Šé™¤ã•ã‚Œã¾ã™

      - name: Invalidate CloudFront Cache
        run: |
          CF_DIST_ID="${{ steps.get_terraform_outputs.outputs.cloudfront_distribution_id }}"
          if [ -z "$CF_DIST_ID" ]; then echo "::error::CloudFront distribution ID not found."; exit 1; fi 
          echo "Invalidating CloudFront cache for distribution: $CF_DIST_ID"

          aws cloudfront create-invalidation --distribution-id "$CF_DIST_ID" --paths "/*"
          # --paths "/*" ã™ã¹ã¦ã®ãƒ‘ã‚¹

      # --- â˜…â˜…â˜… ECS Fargate/ECRã¸ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ â˜…â˜…â˜… ---
      - name: Login to Amazon ECR
        id: login_ecr
        uses: aws-actions/amazon-ecr-login@v2
      - name: Build, Tag, and Push Docker image to ECR
        env:
          ECR_REGISTRY: 258632448142.dkr.ecr.ap-northeast-1.amazonaws.com
          ECR_REPOSITORY: nestjs-hannibal-3

          IMAGE_TAG: ${{ github.sha }}
          # Gitã®ã‚³ãƒŸãƒƒãƒˆã”ã¨ã«è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã€ŒSHA-1ãƒãƒƒã‚·ãƒ¥å€¤ã€ï¼ˆ40æ–‡å­—ã®è‹±æ•°å­—ï¼‰ã§ã™

        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          # ãƒ­ãƒ¼ã‚«ãƒ«ã§ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹
          # -t ã‚¿ã‚°
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
      - name: Update ECS Service to use new image
        env:
          AWS_REGION: ap-northeast-1
          CLUSTER_NAME: nestjs-hannibal-3-cluster
          # Terraformã§ä½œæˆæ¸ˆã¿ã®ãƒªã‚½ãƒ¼ã‚¹ nestjs-hannibal-3-cluster ã‚’ GitHub Actions ã®ç’°å¢ƒå¤‰æ•°ã«æ ¼ç´ã™ã‚‹
          SERVICE_NAME: nestjs-hannibal-3-api-service
          TASK_FAMILY: nestjs-hannibal-3-api-task
          CONTAINER_NAME: nestjs-hannibal-3-container
          IMAGE_TAG: ${{ github.sha }}
          ECR_REGISTRY: 258632448142.dkr.ecr.ap-northeast-1.amazonaws.com
          # AWSã‚¢ã‚«ã‚¦ãƒ³ãƒˆÃ—ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã«1ã¤è‡ªå‹•ã§å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã™
          ECR_REPOSITORY: nestjs-hannibal-3
        run: |

          TASK_DEF_ARN=$(aws ecs describe-services --cluster $CLUSTER_NAME --services $SERVICE_NAME --query "services[0].taskDefinition" --output text)
          # ECSã«ã‚ã‚‹ç¾çŠ¶ã®ã‚¿ã‚¹ã‚¯å®šç¾©ã‚’å–å¾—ã—ã¦ã„ã‚‹
          # ã‚¿ã‚¹ã‚¯å®šç¾© ã©ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ã†ã‹ã€ãƒªã‚½ãƒ¼ã‚¹ã€ç’°å¢ƒå¤‰æ•°ãªã©ã®è¨­è¨ˆå›³
          # services[0] è¿”ã‚Šå€¤ã¯å¿…ãš services ã¨ã„ã†é…åˆ—ã«ãªã‚‹ã®ã§ã€services[0]ã¨æŒ‡å®šã™ã‚‹
          # taskDefinition ã‚¿ã‚¹ã‚¯å®šç¾©ã®ARN
          # ã‚¯ãƒ©ã‚¹ã‚¿åã¨ã‚µãƒ¼ãƒ“ã‚¹åã‚’æŒ‡å®šã™ã‚Œã°ã€ã€Œãã®ã‚µãƒ¼ãƒ“ã‚¹ãŒä½¿ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯å®šç¾©ï¼ˆè¨­è¨ˆå›³ï¼‰ã€ã¯ä¸€æ„ã«ç‰¹å®šã§ãã¾ã™

          aws ecs describe-task-definition --task-definition $TASK_DEF_ARN > task-def.json
          # ã‚¿ã‚¹ã‚¯å®šç¾©ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

          # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ›¸ãæ›ãˆ
          # jqã® | ãƒ‘ã‚¤ãƒ—ã¯ã€Œéƒ¨åˆ†çš„ã«å€¤ã‚’æ›´æ–°ã—ã€å…¨ä½“ã®æ§‹é€ ã‚’ç¶­æŒã™ã‚‹ã€å‹•ãã‚’ã—ã¾ã™
          # ã‚¯ã‚©ãƒ¼ãƒˆã§ããã£ã¦ã‚ã‚‹ç¯„å›²ã¯ã€Œjqã«æ¸¡ã™JSONåŠ å·¥ç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã§ã™

          NEW_IMAGE="$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          cat task-def.json | jq --arg IMAGE "$NEW_IMAGE" --arg NAME "$CONTAINER_NAME" '(.taskDefinition.containerDefinitions[] | select(.name == $NAME) | .image) |= $IMAGE | .taskDefinition | {
            family,
            taskRoleArn,
            executionRoleArn,
            networkMode,
            containerDefinitions,
            volumes,
            placementConstraints,
            requiresCompatibilities,
            cpu,
            memory,
            tags,
            runtimePlatform
          } | with_entries(select(.value != null))' > new-task-def.json
          # {} jqã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ†ãƒ©ãƒ« æŒ‡å®šã—ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã‘ã‚’æŠœãå‡ºã—ã¦æ–°ã—ã„JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œã‚‹
          # aws ecs register-task-definition ã§ã¯ã€å—ã‘ä»˜ã‘ã‚‹JSONã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå³å¯†ã«æ±ºã¾ã£ã¦ã„ã‚‹ãŸã‚ã€ä¸»è¦ãªé …ç›®ã ã‘ã®æ–°ã—ã„JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
          # with_entries ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£(ã‚­ãƒ¼ã¨å€¤ã®ãƒšã‚¢)ã«å‡¦ç†ã‚’è¡Œã†é–¢æ•°ã§ã™
          # select æ¡ä»¶ã«åˆã†è¦ç´ ã ã‘ã‚’æ®‹ã™  é…åˆ— â†’ å„è¦ç´ ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã«å¯¾ã—ã¦ select
          # .taskDefinition.containerDefinitions[] jq ã§ä½¿ã†å ´åˆã€[] ã‚’ã¤ã‘ã‚‹ã¨ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãŒã§ãã‚‹
          # |= ã¯ã€Œéƒ¨åˆ†çš„ãªå€¤ã®æ›´æ–°ã€ã‚’æ„å‘³ã™ã‚‹jqã®æ¼”ç®—å­ã§ã™


          # æ–°ã—ã„ã‚¿ã‚¹ã‚¯å®šç¾©ã‚’ ECS ã«ç™»éŒ²
          TASK_DEF_ARN_NEW=$(aws ecs register-task-definition --cli-input-json file://new-task-def.json --query 'taskDefinition.taskDefinitionArn' --output text)
          # aws ecs register-task-definition æ–°ã—ã„ECSã‚¿ã‚¹ã‚¯å®šç¾©ã‚’ç™»éŒ²ã—ã€ç™»éŒ²ã—ãŸå†…å®¹ã‚’ JSON å½¢å¼ã§è¿”ã™
          # --cli-input-json ã‚³ãƒãƒ³ãƒ‰ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’JSONã§ã¾ã¨ã‚ã¦æ¸¡ã™
          # -query è¿”ã£ã¦ããŸ JSON ã®ä¸€éƒ¨ã‚’æŠ½å‡ºã™ã‚‹
          # taskDefinitionArn ã¯ECSãŒã‚¿ã‚¹ã‚¯å®šç¾©ã‚’ç™»éŒ²ã—ãŸã¨ãã«è‡ªå‹•ã§ä»˜ä¸ã™ã‚‹å€¤ã§ã™

          # ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ–°ã‚¿ã‚¹ã‚¯å®šç¾©ã§æ›´æ–°
          aws ecs update-service --cluster $CLUSTER_NAME --service $SERVICE_NAME --task-definition $TASK_DEF_ARN_NEW
          # ECSãŒæ–°ã—ã„ã‚¤ãƒ¡ãƒ¼ã‚¸ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½œæˆãƒ»èµ·å‹•ã™ã‚‹
          
          # ECSã‚µãƒ¼ãƒ“ã‚¹ã®å®‰å®šåŒ–ã‚’å¾…ã¤
          echo "Waiting for ECS service to stabilize..."
          aws ecs wait services-stable --cluster $CLUSTER_NAME --services $SERVICE_NAME --region $AWS_REGION
          echo "ECS service is now stable"
